{"title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models", "authors": [{"name": "Andy Zhou", "institution": "University of Illinois at Urbana-Champaign", "email": "andyz3@illinois.edu"}, {"name": "Kai Yan", "institution": "University of Illinois at Urbana-Champaign"}, {"name": "Michal Shlapentokh-Rothman", "institution": "University of Illinois at Urbana-Champaign"}, {"name": "Haohan Wang", "institution": "University of Illinois at Urbana-Champaign"}, {"name": "Yu-Xiong Wang", "institution": "University of Illinois at Urbana-Champaign"}], "abstract": "We introduce LATS (Language Agent Tree Search), a general framework that synergizes the capabilities of LLMs in planning, acting, and reasoning. Drawing inspiration from Monte Carlo tree search in model-based reinforcement learning, LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. Our experimental evaluation across diverse domains, such as programming, HotPotQA, and WebShop, illustrates the applicability of LATS for both reasoning and acting.", "keywords": ["language models", "decision-making", "planning", "acting", "reasoning", "Monte Carlo tree search", "LLMs"], "problemStatement": "While large language models (LLMs) have demonstrated impressive performance on a range of decision-making tasks, they rely on simple acting processes and fall short of broad deployment as autonomous agents.", "methodology": "LATS employs LLMs as agents, value functions, and optimizers, repurposing their latent strengths for enhanced decision-making. It uses an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism.", "contributions": ["Introduction of LATS, a general framework that unifies reasoning, acting, and planning in LLMs.", "Experimental evaluation across diverse domains, demonstrating the effectiveness and generality of LATS."], "implementation": {"language": "Python", "repositoryUrl": "https://github.com/andyz245/LanguageAgentTreeSearch", "documentationUrl": "http://lapisrocks.github.io/LanguageAgentTreeSearch/", "requirements": ["transformers", "torch", "numpy"]}, "dataset": {"name": "HumanEval, HotPotQA, WebShop", "description": "Datasets used for evaluating the performance of LATS in programming, question answering, and web interaction tasks."}, "researchOutput": {"conference": "ICML 2024", "metrics": {"HotpotQA (question answering, exact match)": 0.71, "HumanEval (programming, pass@1)": 83.8, "WebShop (web interaction, score)": 75.9}}, "primaryCitation": {"title": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models", "authors": ["Andy Zhou", "Kai Yan", "Michal Shlapentokh-Rothman", "Haohan Wang", "Yu-Xiong Wang"], "venue": "arXiv", "year": 2023, "doi": "2310.04406", "citationsCount": null}, "relatedPublications": [], "status": "completed", "startDate": "2023-10-01", "endDate": "2024-06-30", "fundingSources": []}