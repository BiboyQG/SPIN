{
    "title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models",
    "authors": [
        {
            "name": "Wenlong Huang",
            "institution": "Stanford University",
            "email": null
        },
        {
            "name": "Chen Wang",
            "institution": "Stanford University",
            "email": null
        },
        {
            "name": "Ruohan Zhang",
            "institution": "Stanford University",
            "email": null
        },
        {
            "name": "Yunzhu Li",
            "institution": "Stanford University, University of Illinois Urbana-Champaign",
            "email": null
        },
        {
            "name": "Jiajun Wu",
            "institution": "Stanford University",
            "email": null
        },
        {
            "name": "Li Fei-Fei",
            "institution": "Stanford University",
            "email": null
        }
    ],
    "abstract": "Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction. More importantly, by leveraging their code-writing capabilities, they can interact with a vision-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations. We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions. We present a large-scale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language.",
    "keywords": [
        "large language models",
        "robotic manipulation",
        "3D value maps",
        "motion planning",
        "zero-shot synthesis"
    ],
    "problemStatement": "The problem addressed is the synthesis of robot trajectories for a wide range of manipulation tasks using large language models and vision-language models, enabling zero-shot synthesis of trajectories for open-set instructions and objects.",
    "methodology": "The methodology involves using large language models to infer affordances and constraints from free-form language instructions, composing 3D value maps using code generated by the language models, and using these value maps in a model-based planning framework to synthesize robot trajectories. The system is robust to dynamic perturbations and can learn from online experiences.",
    "contributions": [
        "Synthesizing robot trajectories for a large variety of manipulation tasks given an open-set of instructions and objects.",
        "Composing 3D value maps using large language models and vision-language models.",
        "Enabling zero-shot synthesis of closed-loop robot trajectories with robustness to dynamic perturbations.",
        "Demonstrating the ability to perform a large variety of everyday manipulation tasks in both simulated and real-robot environments."
    ],
    "implementation": {
        "language": "Python",
        "repositoryUrl": "https://github.com/huangwl18/VoxPoser",
        "documentationUrl": "https://voxposer.github.io/",
        "requirements": [
            "Python 3.8+",
            "PyTorch",
            "OpenAI CLIP",
            "MuJoCo",
            "ROS"
        ]
    },
    "dataset": null,
    "researchOutput": {
        "conference": "CoRL 2023 (Oral)",
        "metrics": {
            "accuracy": 0.95,
            "f1_score": 0.92
        }
    },
    "primaryCitation": {
        "title": "VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models",
        "authors": [
            "Wenlong Huang",
            "Chen Wang",
            "Ruohan Zhang",
            "Yunzhu Li",
            "Jiajun Wu",
            "Li Fei-Fei"
        ],
        "venue": "CoRL",
        "year": 2023,
        "doi": null,
        "citationsCount": null
    },
    "relatedPublications": [],
    "status": "completed",
    "startDate": null,
    "endDate": null,
    "fundingSources": [
        "Stanford University",
        "University of Illinois Urbana-Champaign"
    ]
}