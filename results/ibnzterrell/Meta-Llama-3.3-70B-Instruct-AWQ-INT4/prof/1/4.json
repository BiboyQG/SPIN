{"fullname": "Nan Jiang", "title": "Associate Professor", "contact": {"phone": "", "email": "nanjiang@illinois.edu"}, "office": "3322 Siebel Center", "education": [{"degree": "PhD", "field": "Computer Science and Engineering", "institution": "University of Michigan", "year": 2017}], "biography": "Nan Jiang is an expert on machine learning and builds theoretical foundations of reinforcement learning (RL). He focuses on setting function approximations that allow an RL agent to generalize from known states to unknown states for which exact calculations would be infeasible. Jiang earned his Ph.D. in Computer Science and Engineering at the University of Michigan in 2017. He spent a year as a postdoc in Microsoft Research\u2019s Machine Learning Group before joining the Illinois faculty in 2018. He is also a recipient of the 2024 Sloan Research Fellowship. His research focus is a part of the Artificial Intelligence (AI) field, specifically through machine learning (ML). The basic idea of RL concerns the ways in which intelligent agents should take action and is one of three ML prongs, including supervised learning and unsupervised learning. He is currently collaborating with researchers from 10 other universities as part of the new AI Institute for Future Edge Networks and Distributed Intelligence (AI-EDGE).", "professionalHighlights": [{"position": "Associate Professor", "organization": "CS @ UIUC", "yearStart": 2024, "yearEnd": null}, {"position": "Assistant Professor", "organization": "CS @ UIUC", "yearStart": 2018, "yearEnd": 2024}, {"position": "Postdoc Researcher", "organization": "MSR NYC", "yearStart": 2017, "yearEnd": 2018}, {"position": "PhD", "organization": "CSE @ UMich", "yearStart": 2011, "yearEnd": 2017}], "researchStatement": "My research focuses on reinforcement learning, particularly in the function-approximation setting. I am interested in developing theoretical foundations for RL and applying it to various domains, including but not limited to, robotics, game playing, and recommender systems. I have worked on various projects, such as offline reinforcement learning, adversarial reinforcement learning, and reinforcement learning in low-rank MDPs. I am also interested in exploring the applications of RL in real-world problems, such as autonomous driving, smart grids, and personalized medicine. Recently, I have been awarded the NSF CAREER Award for my project entitled \u201cTheoretical Foundations of Offline Reinforcement Learning\u201d that resulted in five years and $500,000 in funding support. I am also part of the AI Institute for Future Edge Networks and Distributed Intelligence (AI-EDGE), where I will focus on exploring how AI can help optimize computer network operations.", "researchInterests": [{"area": "Reinforcement Learning", "description": "I work on building the theoretical foundation of reinforcement learning (RL), especially in the function-approximation setting."}], "researchAreas": ["Artificial Intelligence", "Machine Learning"], "publications": [{"title": "On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation", "authors": ["Yuheng Zhang", "Nan Jiang"], "conference": "NeurIPS-24", "year": 2024}, {"title": "Future-Dependent Value-Based Off-Policy Evaluation in POMDPs", "authors": ["Masatoshi Uehara", "Haruka Kiyohara", "Andrew Bennett", "Victor Chernozhukov", "Nan Jiang", "Nathan Kallus", "Chengchun Shi", "Wen Sun"], "conference": "NeurIPS-23", "year": 2023}, {"title": "Reinforcement Learning in Low-Rank MDPs with Density Features", "authors": ["Audrey Huang", "Jinglin Chen", "Nan Jiang"], "conference": "ICML-23", "year": 2023}, {"title": "Offline Reinforcement Learning with Realizability and Single-policy Concentrability", "authors": ["Wenhao Zhan", "Baihe Huang", "Audrey Huang", "Nan Jiang", "Jason D. Lee"], "conference": "COLT-22", "year": 2022}, {"title": "Adversarially Trained Actor Critic for Offline Reinforcement Learning", "authors": ["Ching-An Cheng", "Tengyang Xie", "Nan Jiang", "Alekh Agarwal"], "conference": "ICML-22", "year": 2022}], "teachingHonors": [{"honor": "Teaching Excellence with Outstanding Award", "year": 2020}, {"honor": "Teaching Excellence", "year": 2022}], "researchHonors": [{"honor": "Google Research Scholar", "organization": "Google", "year": 2024}, {"honor": "Sloan Research Fellowship", "organization": "Sloan Foundation", "year": 2024}, {"honor": "ICML 2022 Outstanding Paper Runner Up", "organization": "ICML", "year": 2022}, {"honor": "NSF CAREER Award", "organization": "NSF", "year": 2022}, {"honor": "AAMAS 2015 Best Paper Award", "organization": "AAMAS", "year": 2015}], "coursesTaught": [{"code": "CS 443", "title": "Reinforcement Learning"}, {"code": "CS 542", "title": "Stat Reinforcement Learning"}, {"code": "CS 598 NJ", "title": "Stat Reinforcement lrng"}]}