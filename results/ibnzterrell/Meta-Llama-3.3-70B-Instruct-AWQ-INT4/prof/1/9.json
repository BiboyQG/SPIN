{"fullname": "Bo Li", "title": "Assistant Professor", "contact": {"phone": "(217) 300-8141", "email": "lbo@illinois.edu"}, "office": "4310 Siebel Center for Comp Sci", "education": [{"degree": "", "field": "", "institution": "University of Illinois at Urbana\u2013Champaign", "year": 0}], "biography": "I am on the advisory board of the Center for Artificial Intelligence Innovation (CAII) at Illinois, and I am a member of the Information Trust Institute (ITI). I am also affiliated with several research centers aiming to broaden the research collaboration and bridge different communities, such as the Advanced Digital Science Center (ADSC), the Center for Cognitive Computing Systems Research (C3SR), and the Quantum Information Science and Technology Center (IQUIST). I also serve in the Accelerated Learning and Engineering Research Training (ALERT) program.", "professionalHighlights": [{"position": "Assistant Professor", "organization": "University of Illinois at Urbana\u2013Champaign", "yearStart": 0, "yearEnd": null}, {"position": "PI for the NSF ACTION Institute", "organization": "NSF ACTION Institute", "yearStart": 2023, "yearEnd": null}], "researchStatement": "My research focuses on trustworthy machine learning, with an emphasis on robustness, privacy, generalization, and their interconnections. We believe that closing today's trustworthiness gap in ML requires us to tackle these grappled problems in a holistic framework, driven by fundamental research focusing on not only each problem but also their underlying interactions. My current research interests include developing novel machine learning algorithms and models that can provide robust and reliable performance in various applications, such as computer vision, natural language processing, and reinforcement learning. I am also interested in exploring the applications of machine learning in real-world problems, including but not limited to, security, privacy, and social good. I have been working on the concept of Trustworthy AI, and my research has led to the development of a framework called 'Learning-Reasoning' which integrates human reasoning into the equation to help mitigate tradeoffs between accuracy and robustness in systems combating machine learning vulnerabilities. I have also been involved in the newly formed NSF AI Institute for Agent-based Cyber Threat Intelligence and OperatioN (ACTION), which aims to revolutionize protection for mission-critical systems against sophisticated cyber threats. As a PI for the NSF ACTION Institute, my work will address research thrusts related to the AI stack, such as knowledge-enabled logic reasoning and multi-agent collaboration, and the AI for cybersecurity thrusts, such as cyber vulnerability assessment, detection, attribution, and recovery. Recently, I have been impressed by the new technology called Neural Voice Camouflage, which generates custom audio noise in the background as you talk, confusing the artificial intelligence (AI) that transcribes our recorded voices.", "researchInterests": [{"area": "Information Theory", "description": ""}, {"area": "Game Theory", "description": ""}, {"area": "Privacy", "description": ""}, {"area": "Trustworthy Machine Learning", "description": ""}, {"area": "Security", "description": ""}, {"area": "Artificial Intelligence", "description": ""}], "researchAreas": ["Artificial Intelligence", "Security and Privacy", "Adversarial Machine Learning", "Big Data", "Social Network"], "publications": [{"title": "Robust physical-world attacks on deep learning visual classification", "authors": ["K Eykholt", "I Evtimov", "E Fernandes", "B Li", "A Rahmati", "C Xiao", "A Prakash"], "conference": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition", "year": 2018}, {"title": "Targeted backdoor attacks on deep learning systems using data poisoning", "authors": ["X Chen", "C Liu", "B Li", "K Lu", "D Song"], "conference": "arXiv preprint arXiv:1712.05526", "year": 2017}, {"title": "Generating adversarial examples with adversarial networks", "authors": ["C Xiao", "B Li", "JY Zhu", "W He", "M Liu", "D Song"], "conference": "arXiv preprint arXiv:1801.02610", "year": 2018}, {"title": "Manipulating machine learning: Poisoning attacks and countermeasures for regression learning", "authors": ["M Jagielski", "A Oprea", "B Biggio", "C Liu", "C Nita-Rotaru", "B Li"], "conference": "2018 IEEE Symposium on Security and Privacy (SP)", "year": 2018}, {"title": "Characterizing adversarial subspaces using local intrinsic dimensionality", "authors": ["X Ma", "B Li", "Y Wang", "SM Erfani", "S Wijewickrema", "G Schoenebeck", "D Song"], "conference": "arXiv preprint arXiv:1801.02613", "year": 2018}], "teachingHonors": [{"honor": "Teachers Ranked as Excellent Award", "year": 2021}], "researchHonors": [{"honor": "IJCAI Computers and Thought Award", "organization": "", "year": 2022}, {"honor": "AI's 10 to Watch", "organization": "", "year": 2022}, {"honor": "Google Faculty Research Award", "organization": "", "year": 2022}, {"honor": "First prize in the International Verification Neural Networks Competition (VNN-COMP'22)", "organization": "", "year": 2022}, {"honor": "Dean's Award for Excellence in Research", "organization": "", "year": 2022}], "coursesTaught": [{"code": "CS 307", "title": "Model & Learning in Data Sci"}, {"code": "CS 442 (CS 498 LB1, CS 498 LB2)", "title": "Trustworthy Machine Learning"}, {"code": "CS 562", "title": "Adv Topics in Sec, Priv and ML"}, {"code": "CS 598 BL", "title": "Adversarial Machine Learning"}]}