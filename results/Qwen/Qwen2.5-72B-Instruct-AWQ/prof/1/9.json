{"fullname": "Bo Li", "title": "Assistant Professor", "contact": {"phone": "(217) 300-8141", "email": "lbo@illinois.edu"}, "office": "4310 Siebel Center for Comp Sci", "education": [{"degree": "PhD", "field": "Computer Science", "institution": "University of Illinois at Urbana-Champaign", "year": 2016}], "biography": "Bo Li is an Assistant Professor in the Department of Computer Science at the University of Illinois at Urbana-Champaign. Her research focuses on trustworthy machine learning, with an emphasis on robustness, privacy, generalization, and their interconnections. She has devised new ways to fool AI, such as creating adversarial attacks that can manipulate input data to fool neural networks. Her goal is to use this knowledge to make AI more robust. She has developed techniques to expose flaws in AI systems and to defend against future attacks. Her work has been applied in commercial applications, including IBM's Watson and Amazon's Alexa, and in autonomous vehicle companies to improve the robustness of their machine-learning models.", "professionalHighlights": [{"position": "Advisory Board Member", "organization": "Center for Artificial Intelligence Innovation (CAII)", "yearStart": 2023, "yearEnd": null}, {"position": "Member", "organization": "Information Trust Institute (ITI)", "yearStart": 2023, "yearEnd": null}, {"position": "Affiliate", "organization": "Advanced Digital Science Center (ADSC)", "yearStart": 2023, "yearEnd": null}, {"position": "Affiliate", "organization": "Center for Cognitive Computing Systems Research (C3SR)", "yearStart": 2023, "yearEnd": null}, {"position": "Affiliate", "organization": "Quantum Information Science and Technology Center (IQUIST)", "yearStart": 2023, "yearEnd": null}, {"position": "Serving in", "organization": "Accelerated Learning and Engineering Research Training (ALERT) program", "yearStart": 2023, "yearEnd": null}, {"position": "Principal Investigator", "organization": "NSF AI Institute for Agent-based Cyber Threat Intelligence and OperatioN (ACTION)", "yearStart": 2023, "yearEnd": null}, {"position": "Winner", "organization": "IJCAI Computers and Thought Award", "yearStart": 2022, "yearEnd": null}, {"position": "2022 Sloan Research Fellow", "organization": "Alfred P. Sloan Foundation", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "Dean's Award for Excellence in Research for Assistant Professor", "yearStart": 2022, "yearEnd": null}, {"position": "AdvML Rising Star Award Winner", "organization": "AdvML-Frontiers workshop at NeurIPS 2024", "yearStart": 2024, "yearEnd": null}, {"position": "Principal Investigator", "organization": "NSF CAREER Award: DeepTrust: Enabling Robust Machine Learning with Exogenous Information", "yearStart": 2021, "yearEnd": 2026}, {"position": "Key Player", "organization": "Facebook's Libra Project", "yearStart": 2017, "yearEnd": null}, {"position": "Winner", "organization": "Outstanding Paper Award at NeurIPS 2023", "yearStart": 2023, "yearEnd": null}, {"position": "Recipient", "organization": "Teachers Ranked as Excellent Award", "yearStart": 2023, "yearEnd": null}, {"position": "Recipient", "organization": "Teachers Ranked as Excellent Award", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "C.W. Gear Outstanding Junior Faculty Award", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "Dean's Award for Excellence in Research", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "Alfred P. Sloan Fellowship in Computer Science", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "IEEE AI's 10 to Watch Award", "yearStart": 2022, "yearEnd": null}, {"position": "Recipient", "organization": "NSF CAREER Award", "yearStart": 2021, "yearEnd": null}, {"position": "Recipient", "organization": "Intel\u2019s 2020 Rising Star Faculty Award", "yearStart": 2020, "yearEnd": null}, {"position": "Recipient", "organization": "NSF CAREER Award", "yearStart": 2020, "yearEnd": null}, {"position": "Recipient", "organization": "MIT Technology Review list of 35 Innovators Under 35, 2020", "yearStart": 2020, "yearEnd": null}, {"position": "Recipient", "organization": "2019 Q4 recipients of AWS Machine Learning Research Awards", "yearStart": 2019, "yearEnd": null}, {"position": "Recipient", "organization": "Google Research Scholar Award", "yearStart": 2021, "yearEnd": null}, {"position": "Recipient", "organization": "2020 recipients of AWS Amazon Research Award", "yearStart": 2020, "yearEnd": null}, {"position": "Recipient", "organization": "2019 Q4 recipients of AWS Machine Learning Research Awards", "yearStart": 2019, "yearEnd": null}, {"position": "Principal Investigator", "organization": "C3.ai Digital Transformation Institute (DTI) Project: Protecting Critical Infrastructures Against Evolving Insider Threats", "yearStart": 2022, "yearEnd": null}, {"position": "Principal Investigator", "organization": "C3.ai Digital Transformation Institute (DTI) Project: REFL: Resilient Distributed Cybersecurity Learning System", "yearStart": 2022, "yearEnd": null}, {"position": "Principal Investigator", "organization": "C3.ai Digital Transformation Institute (DTI) Project: Robust and Scalable Forensics for Deep Neural Networks", "yearStart": 2022, "yearEnd": null}, {"position": "Principal Investigator", "organization": "C3.ai Digital Transformation Institute (DTI) Project: Deep-Learning detection algorithms for advanced persistent attacks in mixed-autonomy traffic: design and experimental validation", "yearStart": 2022, "yearEnd": null}, {"position": "Principal Investigator", "organization": "C3.ai Digital Transformation Institute (DTI) Project: An Intelligence platform for Better Security in Decentralized Finance", "yearStart": 2022, "yearEnd": null}], "researchStatement": "My research focuses on trustworthy machine learning, with an emphasis on robustness, privacy, generalization, and their interconnections. We believe that closing today's trustworthiness gap in ML requires us to tackle these grappled problems in a holistic framework, driven by fundamental research focusing on not only each problem but also their underlying interactions. The long-term goal for our group, Secure learning lab (SL2), is to make machine learning systems robust, private, and generalizable with guarantees for different real-world applications. We have worked on exploring different types of adversarial attacks, including evasion and poisoning attacks in digital and physical worlds, under various constraints. We have developed and will continue to explore robust learning systems based on game-theoretic analysis, knowledge-enabled logical reasoning, and properties of learning tasks. Our work directly benefits applications such as computer vision, natural language processing, safe autonomous driving, and trustworthy federated learning systems.", "researchInterests": [{"area": "Information Theory", "description": ""}, {"area": "Game Theory", "description": ""}, {"area": "Privacy", "description": ""}, {"area": "Trustworthy Machine Learning", "description": ""}, {"area": "Security", "description": ""}, {"area": "Artificial Intelligence", "description": ""}], "researchAreas": ["Artificial Intelligence", "Security and Privacy"], "publications": [{"title": "Robust physical-world attacks on deep learning visual classification", "authors": ["K Eykholt", "I Evtimov", "E Fernandes", "B Li", "A Rahmati", "C Xiao", "A Prakash", "C Hsieh", "F Tramer", "D Eng", "D Evans"], "conference": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "year": 2018}, {"title": "Targeted backdoor attacks on deep learning systems using data poisoning", "authors": ["X Chen", "C Liu", "B Li", "K Lu", "D Song"], "conference": "arXiv preprint arXiv:1712.05526", "year": 2017}, {"title": "Generating adversarial examples with adversarial networks", "authors": ["C Xiao", "B Li", "JY Zhu", "W He", "M Liu", "D Song"], "conference": "arXiv preprint arXiv:1801.02610", "year": 2018}, {"title": "Manipulating machine learning: Poisoning attacks and countermeasures for regression learning", "authors": ["M Jagielski", "A Oprea", "B Biggio", "C Liu", "C Nita-Rotaru", "B Li"], "conference": "2018 IEEE Symposium on Security and Privacy (SP)", "year": 2018}, {"title": "Characterizing adversarial subspaces using local intrinsic dimensionality", "authors": ["X Ma", "B Li", "Y Wang", "SM Erfani", "S Wijewickrema", "G Schoenebeck", "D Song", "C Leckie", "J Hou", "S Tan"], "conference": "arXiv preprint arXiv:1801.02613", "year": 2018}, {"title": "Textbugger: Generating adversarial text against real-world applications", "authors": ["J Li", "S Ji", "T Du", "B Li", "T Wang"], "conference": "arXiv preprint arXiv:1812.05271", "year": 2018}, {"title": "Deepgauge: Multi-granularity testing criteria for deep learning systems", "authors": ["L Ma", "F Juefei-Xu", "F Zhang", "J Sun", "M Xue", "B Li", "C Chen", "T Su", "L Li", "Y Liu", "J Zhao", "S See", "Y Wang", "J Yin"], "conference": "Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering (ASE)", "year": 2018}, {"title": "DBA: Distributed Backdoor Attacks against Federated Learning", "authors": ["C Xie", "K Huang", "PY Chen", "B Li"], "conference": "International Conference on Learning Representations (ICLR)", "year": 2019}, {"title": "Spatially transformed adversarial examples", "authors": ["C Xiao", "JY Zhu", "B Li", "W He", "M Liu", "D Song"], "conference": "arXiv preprint arXiv:1801.02612", "year": 2018}, {"title": "Physical adversarial examples for object detectors", "authors": ["D Song", "K Eykholt", "I Evtimov", "E Fernandes", "B Li", "A Rahmati", "F Tramer", "D Eng", "D Evans"], "conference": "12th USENIX Workshop on Offensive Technologies (WOOT 18)", "year": 2018}, {"title": "The secret revealer: generative model-inversion attacks against deep neural networks", "authors": ["Y Zhang", "R Jia", "H Pei", "W Wang", "B Li", "D Song"], "conference": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "year": 2020}, {"title": "Towards efficient data valuation based on the shapley value", "authors": ["R Jia", "D Dao", "B Wang", "FA Hubis", "N Hynes", "NM G\u00fcrel", "B Li", "C Zhang", "D Song"], "conference": "The 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)", "year": 2019}, {"title": "Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks", "authors": ["Y Li", "X Lyu", "N Koren", "L Lyu", "B Li", "X Ma"], "conference": "arXiv preprint arXiv:2101.05930", "year": 2021}, {"title": "Deephunter: A coverage-guided fuzz testing framework for deep neural networks", "authors": ["X Xie", "L Ma", "F Juefei-Xu", "M Xue", "H Chen", "Y Liu", "J Zhao", "B Li", "J Yin", "S See"], "conference": "Proceedings of the 28th ACM SIGSOFT International Symposium on Software Engineering (FSE)", "year": 2019}, {"title": "Deepmutation: Mutation testing of deep learning systems", "authors": ["L Ma", "F Zhang", "J Sun", "M Xue", "B Li", "F Juefei-Xu", "C Xie", "L Li", "Y Liu", "J Zhao", "S See"], "conference": "2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE)", "year": 2018}, {"title": "Data poisoning attacks on factorization-based collaborative filtering", "authors": ["B Li", "Y Wang", "A Singh", "Y Vorobeychik"], "conference": "Advances in Neural Information Processing Systems (NeurIPS)", "year": 2016}, {"title": "Data Poisoning Attacks on Factorization-based Collaborative Filtering", "authors": ["B Li", "Y Wang", "A Singh", "Y Vorobeychik"], "conference": "Proceedings of the Neural Information Processing Systems (NIPS)", "year": 2016}, {"title": "Towards stable and efficient training of verifiably robust neural networks", "authors": ["H Zhang", "H Chen", "C Xiao", "S Gowal", "R Stanforth", "B Li", "D Boning", "CJ Hsieh"], "conference": "arXiv preprint arXiv:1906.06316", "year": 2019}, {"title": "Adversarial attack and defense on graph data: A survey", "authors": ["L Sun", "Y Dou", "C Yang", "K Zhang", "J Wang", "SY Philip", "L He", "B Li"], "conference": "IEEE Transactions on Knowledge and Data Engineering", "year": 2022}], "teachingHonors": [{"honor": "Teachers Ranked as Excellent Award", "year": 2021}], "researchHonors": [{"honor": "IJCAI Computers and Thought Award", "organization": "IJCAI", "year": 2022}, {"honor": "AI's 10 to Watch", "organization": "AI's 10 to Watch", "year": 2022}, {"honor": "Google Faculty Research Award", "organization": "Google", "year": 2022}, {"honor": "First prize in the International Verification Neural Networks Competition (VNN-COMP'22)", "organization": "VNN-COMP'22", "year": 2022}, {"honor": "Dean's Award for Excellence in Research", "organization": "University of Illinois at Urbana-Champaign", "year": 2022}, {"honor": "C.W. Gear Outstanding Junior Faculty Award", "organization": "University of Illinois at Urbana-Champaign", "year": 2021}, {"honor": "Facebook Research Award", "organization": "Facebook", "year": 2021}, {"honor": "Best Paper Award in EWSN", "organization": "EWSN", "year": 2021}, {"honor": "Intel's 2020 Rising Star Faculty Award", "organization": "Intel", "year": 2020}, {"honor": "Amazon Research Award", "organization": "Amazon", "year": 2020}, {"honor": "NSF CAREER Award", "organization": "NSF", "year": 2020}, {"honor": "MIT Technology Review 35 Innovators Under 35", "organization": "MIT Technology Review", "year": 2020}, {"honor": "Facebook Research Award", "organization": "Facebook", "year": 2019}, {"honor": "Amazon Research Award", "organization": "Amazon", "year": 2019}, {"honor": "IBM Research Award", "organization": "IBM", "year": 2019}, {"honor": "Q4 AWS Machine Learning Research Awards", "organization": "AWS", "year": 2019}], "coursesTaught": [{"code": "CS 307", "title": "Model & Learning in Data Sci"}, {"code": "CS 442 (CS 498 LB1, CS 498 LB2)", "title": "Trustworthy Machine Learning"}, {"code": "CS 562", "title": "Adv Topics in Sec, Priv and ML"}, {"code": "CS 598 BL", "title": "Adversarial Machine Learning"}]}